{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "271228f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Zero-Shot ===\n",
      "supervised learning is a type of learning that is supervised by the teacher. supervised learning is a type of learning that is supervised by the teacher. supervised learning is a type of learning that is supervised by the teacher. supervised learning is a type of learning that is supervised by the teacher. supervised learning is a type of learning that is supervised by the teacher. supervised learning is a type of learning that is supervised by the teacher. supervised learning is a type of learning that is supervised by the teacher.\n",
      "\n",
      "\n",
      "=== Few-Shot ===\n",
      "Unsupervised learning is a type of supervised learning.\n",
      "\n",
      "\n",
      "=== System Prompt ===\n",
      "Unsupervised learning is a method of supervised learning. Unsupervised learning is a method of supervised learning. Unsupervised learning is a method of supervised learning. Unsupervised learning is a method of supervised learning. Unsupervised learning is a method of supervised learning.\n"
     ]
    }
   ],
   "source": [
    "# Day 3 - Prompt Engineering Lab (FLAN-T5 Edition)\n",
    "# Comparing Zero-Shot, Few-Shot, and System Prompts\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load FLAN-T5 small (good balance of size and capability)\n",
    "generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "\n",
    "task = \"Explain the difference between supervised and unsupervised learning in 3 bullet points.\"\n",
    "\n",
    "\n",
    "# 1. Zero-Shot Prompt\n",
    "zero_shot = task\n",
    "print(\"=== Zero-Shot ===\")\n",
    "print(generator(zero_shot,  max_new_tokens=120,      # <-- use only this\n",
    "          do_sample=False,         # deterministic output\n",
    "          clean_up_tokenization_spaces=True)[0][\"generated_text\"])\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# 2. Few-Shot Prompt\n",
    "few_shot = \"\"\"Explain the following in bullet points:\n",
    "\n",
    "Q: What is the difference between classification and regression?\n",
    "A:\n",
    "- Classification predicts discrete labels\n",
    "- Regression predicts continuous values\n",
    "\n",
    "Q: {}\n",
    "A:\"\"\".format(task)\n",
    "\n",
    "print(\"=== Few-Shot ===\")\n",
    "print(generator(few_shot,  max_new_tokens=120,      # <-- use only this\n",
    "          do_sample=False,         # deterministic output\n",
    "          clean_up_tokenization_spaces=True)[0][\"generated_text\"])\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# 3. System Prompt (Role Instruction)\n",
    "system_prompt = \"\"\"You are an expert Machine Learning professor.\n",
    "Always answer clearly in bullet points.\n",
    "\n",
    "Task: {}\n",
    "\"\"\".format(task)\n",
    "\n",
    "print(\"=== System Prompt ===\")\n",
    "print(generator(system_prompt,  max_new_tokens=120,      # <-- use only this\n",
    "          do_sample=False,         # deterministic output\n",
    "          clean_up_tokenization_spaces=True)[0][\"generated_text\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8228b79",
   "metadata": {},
   "source": [
    "# Observations\n",
    "- Zero-shot: Produced repetitive, incorrect text (small model limitation).\n",
    "- Few-shot: Output slightly changed but still wrong.\n",
    "- System: Structured differently but repeated errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6233b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"API key detected:\", len(os.getenv(\"OPENAI_API_KEY\", \"\")) > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a794e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "models = client.models.list()\n",
    "print([m.id for m in models.data[:10]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
